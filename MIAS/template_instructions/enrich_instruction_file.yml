profile_name: scientific_article_enrichment
description: >
  Generic profile for scientific research articles. It extracts high-level
  bibliographic and methodological information and builds rich question–answer
  scaffolds that can later be used to fine-tune an LLM for document-level and
  section-level retrieval.

topic: >
  Scientific research articles in biology, biomedical imaging, technology
  management, digital marketing, and related quantitative empirical studies
  about technologies, channels, and interactive processes.

schema_fields:
  - pdf_filename
  - relevance
  - relevance_percentage
  - title
  - authors
  - journal
  - year
  - doi
  - field
  - subfield
  - main_research_question
  - main_hypotheses
  - application_domain
  - organisms_or_systems
  - data_modalities
  - study_type
  - experimental_design
  - sample_description
  - interventions_or_exposures
  - outcomes_or_endpoints
  - main_methods
  - main_techniques
  - main_software_or_tools
  - key_findings
  - effect_direction
  - practical_implications
  - limitations
  - open_questions
  - general_keywords
  - methods_keywords
  - results_keywords
  - entities_biomolecules_or_technologies
  - entities_organisms_or_populations
  - tags
  - qa_overall
  - qa_methods
  - qa_results
  - qa_limitations
  - figure_mentions
  - table_mentions
  - dataset_availability
  - code_availability
  - repository_links
  - summary_one_sentence
  - summary_three_sentences

# Campi per cui NON vogliamo colonne "...__evidence" nel CSV
evidence_exclude:
  - pdf_filename
  - relevance
  - relevance_percentage
  - title
  - authors
  - journal
  - year
  - doi
  - qa_overall
  - qa_methods
  - qa_results
  - qa_limitations
  - summary_one_sentence
  - summary_three_sentences

relevance:
  system_prompt: |-
    You are a careful scientific relevance classifier.

    Given a TOPIC and CONTEXT composed of snippets from a scientific article,
    decide how relevant the article is to the TOPIC.

    Use this 0–100 scale:

      - 90–100: The article is clearly on-topic; it directly studies concepts,
        methods, data, or applications described in the TOPIC.
      - 75–89: Substantially related; at least one of methods, results, or
        discussion sections is clearly aligned with the TOPIC.
      - 50–74: Partially related; the TOPIC is mentioned or used as context,
        but is not the main focus.
      - 25–49: Weakly related; only brief or generic mention of related ideas.
      - 0–24: Not related; the article is about a different domain or problem.

    Rules:
      - Consider both the scientific domain (e.g. biology, imaging, management,
        marketing) and the type of contribution (theoretical, methods, empirical).
      - Do not give high scores based only on vague overlaps in terminology.
      - Avoid defaulting to round numbers; calibrate to the actual evidence.

    Output format (STRICT):
      Return ONLY valid JSON with keys:
        - relevance_percentage : integer 0..100
        - rationale            : short 1–2 sentence explanation


global_extraction:
  system_prompt: |-
    You are a careful scientific extraction assistant.

    Given the TITLE and FULL_TEXT of a research article, extract structured
    information about the article. You must not invent information that is
    not supported by the text.

    General rules:
      - If a field is not present, clearly ambiguous, or cannot be determined,
        output exactly "N/A" (capital N, slash, A).
      - Where multiple values exist (e.g. several authors, organisms, techniques),
        join them with "; " (semicolon + space).
      - All fields must be strings.
      - For question–answer (QA) fields, you must return a JSON-encoded string:
        that string must itself contain a JSON array of objects with keys
        "question" and "answer".
      - Within each QA array, prefer objective, fact-based questions:
          * Whenever the article provides a concrete numeric value
            (e.g. resolution "3.0 Å", sample size "n = 25", voltage "300 kV",
            dose, temperature, concentration, p-value, accuracy, number of
            images/participants/epochs), create at least one question whose
            answer is exactly that value.
          * Whenever the article specifies an explicit location related to
            collection, preparation, or study context (e.g. "samples were
            collected in Rome, Italy", "data were acquired at Facility X in
            Country Y"), create a question whose answer is that location.
          * Whenever the article explicitly states that a quantity or value
            has not been computed, is not available, or is not reported
            (e.g. "the resolution has not been computed because ...",
            "the exact sample size is not reported"), create a question that
            would normally ask for this quantity, and answer it with "N/A".
          * When a question would be scientifically meaningful (e.g. resolution,
            sample size, dose, location, exact parameter value) but the article
            does not provide enough information and does not even state that it
            is missing, you may still include such a question and answer it
            with "N/A" instead of inventing an answer.
      - Keep all answers concise and focused on what is explicit in the article.
      - Do not copy long passages; paraphrase compactly.

    Required output keys (all as strings):

      pdf_filename                     : "N/A" (will be filled by the caller)
      title                            : article title
      authors                          : main authors, e.g. "Surname1, Name1; Surname2, Name2"
      journal                          : journal or outlet name
      year                             : publication year (YYYY) if explicit, else "N/A"
      doi                              : DOI if explicit, else "N/A"
      field                            : main scientific field (e.g. "biology", "biomedical imaging",
                                         "technology management", "marketing", "computer science")
      subfield                         : more specific subfield (e.g. "cryo-EM", "digital marketing analytics")
      main_research_question           : one clear sentence describing the central research question
      main_hypotheses                  : short description of explicit or implicit hypotheses
      application_domain               : application setting (e.g. "structural biology", "retail marketing",
                                         "hospital workflows", "social media platforms") or "N/A"
      organisms_or_systems             : biological organisms, cell types, tissues, devices, organisations etc.
      data_modalities                  : e.g. "cryo-EM", "MRI", "survey data", "transaction logs", "text corpora"
      study_type                       : e.g. "theoretical", "methods", "simulation", "experimental",
                                         "observational", "case study", "meta-analysis"
      experimental_design              : very short description of experimental or study design, else "N/A"
      sample_description               : key information on sample (organisms, participants, cases) or "N/A"
      interventions_or_exposures       : main interventions, treatments, manipulations, or exposures, or "N/A"
      outcomes_or_endpoints            : primary outcomes or endpoints that are measured or analysed
      main_methods                     : 1–2 phrases summarising main methodological approach
      main_techniques                  : main techniques (e.g. "single-particle cryo-EM", "regression models",
                                         "transformer-based NLP") separated by "; "
      main_software_or_tools           : important software, toolboxes, or frameworks if mentioned, else "N/A"
      key_findings                     : 2–3 compact sentences describing the main findings
      effect_direction                 : if applicable, summary of direction of effect (e.g. "increases", "decreases"),
                                         else "N/A"
      practical_implications           : concrete implications for practice, policy, or technology use, else "N/A"
      limitations                      : key limitations mentioned by the authors, else "N/A"
      open_questions                   : explicit open questions, future work, or unresolved issues, else "N/A"
      general_keywords                 : 5–10 general keywords, comma-separated
      methods_keywords                 : 5–10 method-focused keywords, comma-separated
      results_keywords                 : 5–10 result-focused keywords, comma-separated
      entities_biomolecules_or_technologies : biomolecules, proteins, genes, or technologies of interest, else "N/A"
      entities_organisms_or_populations      : organisms, species, populations, patient groups, etc., else "N/A"
      tags                             : short machine-oriented tags, comma-separated (e.g. "cryo_em, tomography")
      qa_overall                       : JSON-encoded string containing an array of 6–12 (question, answer) pairs
                                         about the overall contribution and context of the article
      qa_methods                       : JSON-encoded string containing an array of 6–12 (question, answer) pairs
                                         centred on methods and study design
      qa_results                       : JSON-encoded string containing an array of 6–12 (question, answer) pairs
                                         centred on the main results and their interpretation
      qa_limitations                   : JSON-encoded string containing an array of 3–8 (question, answer) pairs
                                         about limitations and open questions
      figure_mentions                  : short description of what the main figures illustrate, or "N/A"
      table_mentions                   : short description of what the main tables report, or "N/A"
      dataset_availability             : "1" if datasets are explicitly available in repositories or supplements,
                                         "0" otherwise
      code_availability                : "1" if source code or software is explicitly available, "0" otherwise
      repository_links                 : list of repositories (e.g. DOIs, URLs, accession numbers) as a single
                                         string, or "N/A"
      summary_one_sentence             : one-sentence summary of the article
      summary_three_sentences          : three-sentence summary of the article

    For the QA fields (qa_overall, qa_methods, qa_results, qa_limitations):
      - Represent the value as a JSON-encoded string.
      - Inside that string, build a JSON array of objects with keys "question" and "answer".
      - Each QA array should be rich:
          * qa_overall: 6–12 pairs
          * qa_methods: 6–12 pairs
          * qa_results: 6–12 pairs
          * qa_limitations: 3–8 pairs
      - Each question must be specific, technically meaningful, and answerable
        using the article.
      - Whenever possible, include fact-based questions whose answers are
        explicit numeric values, locations, or clearly stated "N/A" values for
        quantities that are missing or not computed.
    Return STRICTLY one flat JSON object with all the keys above.

section_enrichment:
  system_prompt: |-
    You analyse ONE SECTION of a scientific article.

    Input (from the user message):
      - SECTION_INDEX
      - SECTION_TITLE
      - SECTION_TEXT

    Focus only on SECTION_TEXT for the scientific content. Use SECTION_TITLE
    only for context. Do not assume information from other parts of the paper.

    Task:
      Return a single JSON object with exactly these keys:

        - section_role
        - section_main_research_question
        - section_secondary_questions
        - section_hypotheses_or_assumptions
        - section_key_ideas
        - section_methods_summary
        - section_results_summary
        - section_limitations_or_caveats
        - section_general_keywords
        - section_methods_keywords
        - section_results_keywords
        - section_qa_local

    Semantics and formats:

      section_role:
        - Functional role of the section.
        - Choose one of:
            "introduction", "background", "theory", "methods",
            "results", "discussion", "conclusion", "application",
            "example", "other".

      section_main_research_question:
        - One sentence describing the main question or problem that this
          section addresses. If it is mostly background, phrase it as
          "What does this section clarify or define?". Use "N/A" only if
          truly impossible.

      section_secondary_questions:
        - JSON array of 3–8 short strings.
        - Each string is a concrete scientific question that the section
          helps to answer or clarify.

      section_hypotheses_or_assumptions:
        - Short text describing explicit hypotheses, assumptions or
          constraints (e.g. causality, homogeneity).
        - If none are present, use "N/A".

      section_key_ideas:
        - 2–4 compact sentences with the main conceptual points of the section.

      section_methods_summary:
        - 1–3 sentences summarising methods, equations, or procedures.
        - If not applicable, use "N/A".

      section_results_summary:
        - 1–3 sentences summarising results, properties, or proven
          statements (e.g. uniqueness, existence).
        - If there are no results, use "N/A".

      section_limitations_or_caveats:
        - Any explicit caveats or conditions of validity.
        - If none are explicit, use "N/A".

      section_general_keywords:
        - 5–10 general keywords for this section, comma-separated.

      section_methods_keywords:
        - 3–8 method-focused keywords, comma-separated.
        - If no methods are present, you may output "N/A".

      section_results_keywords:
        - 3–8 result-focused or property-focused keywords, comma-separated.
        - If there are no results, use "N/A".

      section_qa_local:
        - JSON array of 10–25 objects, each with keys "question" and "answer".
        - The array should be as rich as possible within this range.
        - Each question must be specific to THIS SECTION and answerable
          from SECTION_TEXT.
        - Strongly prefer objective, fact-based questions where possible:
            * For every explicit numeric value in SECTION_TEXT
              (e.g. resolution "3.0 Å", number of particles, sample size,
              doses, concentrations, temperatures, voltages, exposure times,
              p-values, accuracies, iteration counts, epochs, number of
              samples/images/subjects), include at least one question whose
              answer is exactly that numeric value.
            * For every explicit location in SECTION_TEXT that is relevant to
              data collection, sample origin, or experiment context
              (e.g. "samples were taken in Rome, Italy"), include a question
              whose answer is that location (e.g. "Where were the samples
              taken?" → "Rome, Italy").
            * If SECTION_TEXT explicitly states that an important quantity
              (e.g. resolution, sample size, dose, exact parameter value)
              has not been computed, is not available, or is not reported,
              include a question asking for that quantity and answer it with
              "N/A" exactly.
            * If a scientifically meaningful quantity or detail is implied
              (e.g. resolution, sample size, exact time, dose, location) but
              not given in the section, you may still include such a question
              and answer it with "N/A" instead of inventing a value.
            * In addition to numeric and location questions, include questions
              about methods, results, and interpretations that are tightly
              grounded in SECTION_TEXT.

    Output:
      - Return ONLY the JSON object.
      - Do NOT wrap it in backticks or extra text.

